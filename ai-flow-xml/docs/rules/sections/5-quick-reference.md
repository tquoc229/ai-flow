# Section 5: Quick Reference - Instructions

<critical>This document provides a quick reference for common patterns, commands, and checklists. Adherence is mandatory to ensure process consistency.</critical>
<critical>This is Section 5 of the AI Coding Agent Project Policy.</critical>

<workflow>

<step n="1" goal="Review Pattern 1: Starting a New PBI">
    <action>
        Follow this step-by-step process to start a new PBI:
        ```
        1. Create PBI entry in backlog.md
           â”œâ”€ Assign unique ID (sequential)
           â”œâ”€ Write user story: "As a [actor], I want [goal], so that [benefit]"
           â”œâ”€ Define Conditions of Satisfaction
           â””â”€ Set status to Proposed

        2. User reviews and approves
           â””â”€ Status: Proposed â†’ Agreed

        3. AI_Agent creates PBI structure
           â”œâ”€ Create: docs/delivery/<PBI-ID>/prd.md
           â”œâ”€ Create: docs/delivery/<PBI-ID>/tasks.md
           â”œâ”€ Populate all required sections
           â”œâ”€ Set up bidirectional linking
           â””â”€ Log approval in PBI history

        4. Define tasks in tasks.md
           â”œâ”€ Break down PBI into atomic tasks
           â”œâ”€ Create task file for each: <PBI-ID>-<TASK-ID>.md
           â”œâ”€ Link tasks in task index
           â””â”€ All tasks start as Proposed

        5. Ready to start implementation
           â””â”€ PBI status: Agreed â†’ InProgress
        ```
    </action>
</step>

<step n="2" goal="Review Pattern 2: Working on a Task">
    <action>
        Follow this complete workflow when working on a task:
        ```
        Step 1: Pre-Work Validation
        â”œâ”€ Check task exists in both task file AND index
        â”œâ”€ Verify status is "Agreed" in both locations
        â”œâ”€ Confirm no other tasks are "InProgress" for same PBI
        â””â”€ Review implementation plan is clear

        Step 2: Start Work (Agreed â†’ InProgress)
        â”œâ”€ AI_Agent updates status to "InProgress" in BOTH locations
        â”œâ”€ Log start event in task history with timestamp
        â”œâ”€ Create feature branch (if using version control)
        â””â”€ Begin implementing according to plan

        Step 3: During Implementation
        â”œâ”€ Follow the implementation plan step by step
        â”œâ”€ Only make changes within task scope
        â”œâ”€ Run tests continuously as you code
        â”œâ”€ Document all files you modify
        â””â”€ Include task ID in every commit message

        Step 4: Submit for Review (InProgress â†’ Review)
        â”œâ”€ Verify all requirements are implemented
        â”œâ”€ Run complete test suite - all must pass
        â”œâ”€ Update task file with implementation details
        â”œâ”€ List all modified files in task documentation
        â”œâ”€ Update status to "Review" in BOTH locations
        â”œâ”€ Notify User that task is ready
        â””â”€ Log submission in task history

        Step 5: User Reviews Task
        â”œâ”€ If User Approves (Review â†’ Done):
        â”‚  â”œâ”€ Review next tasks - are they still relevant?
        â”‚  â”œâ”€ Confirm with User about next tasks
        â”‚  â”œâ”€ Update status to "Done" in BOTH locations
        â”‚  â”œâ”€ Run: git acp "<task-id> <description>"
        â”‚  â””â”€ Log completion with timestamp
        â”‚
        â””â”€ If User Rejects (Review â†’ InProgress):
           â”œâ”€ Document specific rejection reasons
           â”œâ”€ Update task with User's feedback
           â”œâ”€ Update status to "InProgress" in BOTH locations
           â””â”€ Resume work to fix issues
        ```
    </action>
    <action>
        Internalize these key points:
        - âœ… ALWAYS update both task file AND index together
        - âœ… NEVER have two tasks InProgress for same PBI
        - âœ… ALWAYS log status changes with timestamp
        - âœ… ALWAYS reference task ID in commits
    </action>
</step>

<step n="3" goal="Review Pattern 3: Handling Blocked Tasks">
    <action>
        Follow this complete workflow for handling blocked tasks:
        ```
        Step 1: Task Gets Blocked
        â”œâ”€ Identify what is preventing progress:
        â”‚  â”œâ”€ External dependency not available?
        â”‚  â”œâ”€ Waiting for User decision?
        â”‚  â”œâ”€ Technical issue can't be resolved?
        â”‚  â””â”€ Missing critical information?
        â””â”€ Stop all work immediately

        Step 2: Mark Task as Blocked (InProgress â†’ Blocked)
        â”œâ”€ Document the specific blocking reason clearly:
        â”‚  â”œâ”€ What exactly is blocking?
        â”‚  â”œâ”€ What dependency is missing?
        â”‚  â”œâ”€ What decision is needed from User?
        â”‚  â””â”€ What information is required?
        â”œâ”€ Update status to "Blocked" in BOTH locations
        â”œâ”€ Log blocking event in task history
        â””â”€ Notify User immediately with blocking details

        Step 3: While Task is Blocked
        â”œâ”€ Monitor the blocker for resolution
        â”œâ”€ Keep User updated on any changes
        â”œâ”€ Create new tasks to address blocker (if you can)
        â””â”€ Do NOT work on this task until unblocked

        Step 4: Blocker Gets Resolved
        â”œâ”€ Verify the blocker is fully resolved
        â”œâ”€ Dependency is now available OR
        â”œâ”€ User has made the decision OR
        â””â”€ Technical issue is fixed

        Step 5: Unblock Task (Blocked â†’ InProgress)
        â”œâ”€ Document how blocker was resolved
        â”œâ”€ Update task file with resolution details
        â”œâ”€ Update status to "InProgress" in BOTH locations
        â”œâ”€ Log unblocking event in task history
        â”œâ”€ Resume work from where you stopped
        â””â”€ Notify User and stakeholders work resumed
        ```
    </action>
    <action>
        Recognize common blocking reasons:
        - ğŸ”´ Waiting for external API credentials
        - ğŸ”´ User needs to make architectural decision
        - ğŸ”´ Dependency on another team's work
        - ğŸ”´ Required third-party service unavailable
        - ğŸ”´ Missing design specifications
        - ğŸ”´ Technical limitation discovered
    </action>
    <action>
        Follow these rules while a task is blocked:
        - âœ… Document everything about the blocker
        - âœ… Propose solutions if possible
        - âœ… Work on other non-blocked tasks (different PBI)
        - âŒ Do NOT try to work around the blocker
        - âŒ Do NOT start other tasks in same PBI
    </action>
</step>

<step n="4" goal="Review Pattern 4: Creating Task Documentation">
    <action>
        Use this template for all task documentation files:
        ```markdown
        ---
        priority: medium
        created: YYYY-MM-DD
        updated: YYYY-MM-DD
        estimated_hours: X
        ---
        # Task: [Task-ID] [Task-Name]
        [Back to task list](tasks.md)

        ## Goal
        [What this task achieves]

        ## Context
        [Why we're doing this]

        ## Status History
        | Timestamp | Action | From Status | To Status | Details | User |
        |-----------|---------|---------|---------|---------|---------|
        | ... | ... | ... | ... | ... | ... |

        ## Requirements
        - [ ] Requirement 1
        - [ ] Requirement 2

        ## Implementation Steps
        1. Step 1: [Description]
         - ...
        2. Step 2: [Description]
         - ...

        ## Files to Modify/Create
        - [ ] path/to/file1.js - [What to do]
        - [ ] path/to/new-file.ts - [Create new]

        ## Testing
        **Test Cases**:
        - [ ] Test case 1
        - [ ] Test case 2

        ## Success Criteria
        - [ ] Implementation complete
        - [ ] Tests passing
        - [ ] Code follows standards

        ## References
        [Links to relevant docs]
        ```
    </action>
</step>

<step n="5" goal="Review Pattern 5: Status Synchronization Check">
    <action>
        Execute this validation logic before ANY status change:
        ```javascript
        // Pseudo-code for validation
        function validateStatusChange(taskId, newStatus) {
          // 1. Read status from task file
          const fileStatus = readTaskFile(taskId).status;

          // 2. Read status from index
          const indexStatus = readTaskIndex(taskId).status;

          // 3. Verify they match
          if (fileStatus !== indexStatus) {
            throw new Error(
              `Status mismatch for ${taskId}:
               File: ${fileStatus}, Index: ${indexStatus}`
            );
          }

          // 4. Verify transition is valid
          if (!isValidTransition(fileStatus, newStatus)) {
            throw new Error(
              `Invalid transition: ${fileStatus} â†’ ${newStatus}`
            );
          }

          // 5. Update both atomically
          updateTaskFile(taskId, newStatus);
          updateTaskIndex(taskId, newStatus);
          logHistoryEntry(taskId, fileStatus, newStatus);
        }
        ```
    </action>
</step>

<step n="6" goal="Review Pattern 6: External Package Integration">
    <action>
        Follow this process when integrating a new external package:
        ```
        1. Research First
           â”œâ”€ Search official documentation
           â”œâ”€ Understand API usage
           â”œâ”€ Check compatibility
           â””â”€ Review examples

        2. Create Package Guide
           â”œâ”€ File: tasks/<task-id>-<package-name>-guide.md
           â”œâ”€ Date stamp the document
           â”œâ”€ Link to original docs
           â”œâ”€ Include API usage examples
           â”œâ”€ Add code snippets in project language
           â””â”€ Document gotchas and best practices

        3. Reference in Task
           â”œâ”€ Link package guide from task file
           â”œâ”€ Use guide as implementation reference
           â””â”€ Update guide if API changes

        Example:
        Task 2-1 using pg-boss
        â”œâ”€ Create: tasks/2-1-pg-boss-guide.md
        â”œâ”€ Document pg-boss API usage
        â””â”€ Reference in task 2-1.md
        ```
    </action>
</step>

<step n="7" goal="Review Common Commands and Patterns">
    <action>
        Use this Git workflow for task completion:
        ```bash
        # When task moves to Done status, use the format from config.yaml:
        # {automation.commit_message_format}

        # Option 1: Using automation helper
        git acp "feat(1): 1-7 Add pino logging"

        # Option 2: Manual steps
        git add .
        git commit -m "feat(1): 1-7 Add pino logging"
        git push origin feature/1-7-add-pino-logging
        ```
    </action>
    <action>
        Use these commands to create a new PBI structure:
        ```bash
        # After PBI approved (Proposed â†’ Agreed)

        # Create directory
        mkdir -p docs/delivery/<PBI-ID>

        # Create files
        touch docs/delivery/<PBI-ID>/prd.md
        touch docs/delivery/<PBI-ID>/tasks.md

        # Populate templates
        # - prd.md: Use PBI detail template (Section 3.6)
        # - tasks.md: Use task index template (Section 4.10)
        ```
    </action>
    <action>
        Use these commands to check for task status mismatches:
        ```bash
        # Check for status mismatches

        # 1. Read task file status
        grep "Status" docs/delivery/<PBI-ID>/<PBI-ID>-<TASK-ID>.md

        # 2. Read index status
        grep "<TASK-ID>" docs/delivery/<PBI-ID>/tasks.md

        # 3. Compare - they must match!
        ```
    </action>
</step>

<step n="8" goal="Review Decision Tree: Should I Search for Package Documentation?">
    <action>
        Follow this decision tree before using an external package:
        ```
        Are you about to use an external package?
            â†“
          YES â†’ Do you fully understand its API?
            â†“              â†“
           NO             YES
            â†“              â†“
        Search web     Verify your
        for official   understanding
        docs first     is current
            â†“              â†“
        Create package  Proceed with
        guide document  implementation
        ```
    </action>
</step>

<step n="9" goal="Review Decision Tree: What Test Plan Detail Level?">
    <action>
        Follow this decision tree to determine the required level of detail for a test plan:
        ```
        Assess task complexity
            â†“
        Simple? (constants, interfaces, config)
            â†“
          YES â†’ Minimal test plan
            |   - Objective
            |   - Success criteria
            â†“
           NO
            â†“
        Basic? (simple functions, CRUD)
            â†“
          YES â†’ Moderate test plan
            |   - Objective
            |   - Test scope
            |   - 3-5 scenarios
            |   - Success criteria
            â†“
           NO
            â†“
        Complex? (multi-service, complex logic)
            â†“
          YES â†’ Detailed test plan
                - Objective
                - Test scope
                - Environment & setup
                - Mocking strategy
                - 5-10 scenarios
                - Edge cases
                - Success criteria
        ```
    </action>
</step>

<step n="10" goal="Review Decision Tree: Can I Start This Task?">
    <action>
        Follow this step-by-step decision process before starting any task:
        ```
        Question 1: Is the task status "Agreed"?
            â†“
           NO â†’ âŒ STOP. You cannot start this task.
            |   â†’ The task needs User approval first.
            |   â†’ Wait for User to review and approve.
            â†“
          YES â†’ Continue to next check
            â†“

        Question 2: Does the status match in BOTH locations?
            â†“
            Check task file status: _______
            Check index file status: _______
            â†“
           NO â†’ âŒ STOP. Status mismatch detected!
            |   â†’ Report this issue to User immediately.
            |   â†’ Provide details: which file has which status.
            |   â†’ Wait for User to fix synchronization.
            â†“
          YES â†’ Continue to next check
            â†“

        Question 3: Are there any other tasks "InProgress" for this PBI?
            â†“
          YES â†’ âŒ STOP. Cannot start this task.
            |   â†’ Only ONE task per PBI can be InProgress.
            |   â†’ Report which other task is InProgress.
            |   â†’ Wait for that task to complete first.
            â†“
           NO â†’ Continue to next check
            â†“

        Question 4: Are all dependencies available?
            â†“
           NO â†’ âŒ STOP. Task is blocked.
            |   â†’ Mark task as Blocked.
            |   â†’ Document what dependencies are missing.
            |   â†’ Notify User about the blocker.
            â†“
          YES â†’ âœ… All checks passed!
            â†“

            âœ… You can start this task!
            â†“
            Proceed with "Starting Work on Task" transition:
            1. Update status to "InProgress" in BOTH locations
            2. Log start event in task history
            3. Begin implementation
        ```
    </action>
    <action>
        Use this quick checklist before starting work:
        - [ ] Task status is "Agreed" âœ…
        - [ ] Status matches in task file and index âœ…
        - [ ] No other tasks "InProgress" for this PBI âœ…
        - [ ] All dependencies available âœ…

        If ALL checked â†’ Start work!
    </action>
</step>

<step n="11" goal="Review Validation Checklists">
    <action>
        Use this checklist before starting ANY task:
        - [ ] Task exists in task file (`<PBI-ID>-<TASK-ID>.md`)
        - [ ] Task exists in task index (`tasks.md`)
        - [ ] Status is `Agreed` in task file
        - [ ] Status is `Agreed` in task index
        - [ ] No other tasks `InProgress` for this PBI
        - [ ] All dependencies are available
        - [ ] Implementation plan is clear
        - [ ] Test plan is defined
    </action>
    <action>
        Use this checklist before submitting a task for review:
        - [ ] All requirements implemented
        - [ ] All tests written and passing
        - [ ] Test plan requirements met
        - [ ] Code follows project standards
        - [ ] Files modified documented in task file
        - [ ] Task documentation updated with implementation details
        - [ ] No scope creep (all changes within task scope)
        - [ ] Commits reference task ID
    </action>
    <action>
        Use this checklist before marking a task as Done:
        - [ ] User has reviewed and approved
        - [ ] All acceptance criteria verified
        - [ ] All tests passing
        - [ ] Status updated in BOTH locations
        - [ ] Next tasks reviewed for relevance
        - [ ] User confirmed about next tasks
        - [ ] Version control workflow executed
        - [ ] Completion logged in history
    </action>
    <action>
        Use this checklist before marking a PBI as Done:
        - [ ] ALL tasks have status `Done`
        - [ ] All Conditions of Satisfaction met
        - [ ] Full test suite passing
        - [ ] Documentation updated
        - [ ] E2E CoS test completed and passing
        - [ ] User approval received
        - [ ] Completion date recorded
        - [ ] History logged
    </action>
</step>

<step n="12" goal="Review Common Pitfalls to Avoid">
    <action>
        Avoid these File Management pitfalls:
        - âŒ **Creating files without User confirmation**: Always get explicit approval for new standalone files.
        - âŒ **Orphaned task files**: Every task in the index MUST have a corresponding markdown file.
        - âŒ **Broken links**: Use relative paths and test all links.
    </action>
    <action>
        Avoid these Status Management pitfalls:
        - âŒ **Updating only one location**: ALWAYS update both the task file AND index atomically.
        - âŒ **Skipping status history**: ALWAYS log status changes with a timestamp.
        - âŒ **Invalid transitions**: Follow the defined workflow states.
    </action>
    <action>
        Avoid these Workflow pitfalls:
        - âŒ **Multiple InProgress tasks**: Only ONE task per PBI should be InProgress.
        - âŒ **Scope creep**: Stay within the defined task scope. Create new tasks for additional work.
        - âŒ **Missing User approval**: Never start work on `Proposed` tasks.
    </action>
    <action>
        Avoid these Testing pitfalls:
        - âŒ **Over-engineering simple test plans**: Match test plan detail to task complexity.
        - âŒ **Skipping E2E CoS test task**: Every PBI MUST have a dedicated E2E testing task.
        - âŒ **Testing package APIs directly**: Do not test external package methods in your unit tests.
    </action>
    <action>
        Avoid these Documentation pitfalls:
        - âŒ **Duplicating information**: Follow the DRY principle; reference instead of duplicating.
        - âŒ **Using magic numbers**: Define constants for repeated or special values.
        - âŒ **Missing package guides**: Always create a guide when using a new package.
    </action>
</step>

<step n="13" goal="Review Best Practices Summary">
    <action>
        Adhere to these Process Best Practices:
        1. **Always verify before acting**: Check status, validate transitions, confirm no conflicts.
        2. **Keep tasks small and focused**: Break down complex features into atomic units.
        3. **Document as you go**: Keep documentation current in real-time.
        4. **Synchronize atomically**: Update related files in the same commit.
    </action>
    <action>
        Adhere to these Code Best Practices:
        1. **Use constants for values**: Define once, reference everywhere.
        2. **Follow DRY principle**: Maintain a single source of truth.
        3. **Reference task ID in commits**: Ensure every commit is traceable to a task.
        4. **Stay within scope**: Only make changes authorized by the task.
    </action>
    <action>
        Adhere to these Testing Best Practices:
        1. **Match test plan to complexity**: Don't over-engineer simple test plans.
        2. **Use real infrastructure for integration**: Mock only external third-party services.
        3. **Focus E2E on critical paths**: Reserve E2E tests for important user workflows.
        4. **Automate all tests**: Ensure consistent verification and fast feedback.
    </action>
    <action>
        Adhere to these Communication Best Practices:
        1. **Ask when uncertain**: Never assume user intent; clarify ambiguous requirements.
        2. **Report issues immediately**: Don't hide problems; stop work when blocked.
        3. **Review next tasks**: Confirm relevance with the user before finishing the current task.
        4. **Keep stakeholders informed**: Notify on status changes, blockers, and completions.
    </action>
</step>

<step n="14" goal="Navigate Between Sections">
    <action>Use the following links to navigate the policy documents:</action>
    - [â† Back to Index](../project-policy-index.md)
    - [â† Previous: Section 4 - Testing Strategy](./4-testing-strategy.md)
</step>

</workflow>